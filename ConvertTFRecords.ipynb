{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import pickle\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils import text_process_aihub as aihub_text\n",
    "from utils.transform import transform_mfcc_from_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_list(path, audio_ext='.pcm', trans_ext='.txt'):\n",
    "    if not os.path.exists(path):\n",
    "        return []\n",
    "    \n",
    "    file_list = []\n",
    "    for _path, _dir, _files in os.walk(path):\n",
    "        for f in _files:\n",
    "            if f[-len(audio_ext):] == audio_ext:\n",
    "                f_name = os.path.join(_path, f[:-len(audio_ext)])\n",
    "                if os.path.exists(f_name + trans_ext):\n",
    "                    file_list.append(f_name)\n",
    "    file_list.sort()\n",
    "    \n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/KsponSpeech_sample/KsponSpeech_000001',\n",
       " 'data/KsponSpeech_sample/KsponSpeech_000002']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"data/KsponSpeech_sample/\"\n",
    "audio_ext = '.pcm'\n",
    "trans_ext = '.txt'\n",
    "\n",
    "file_list = get_file_list(data_dir, audio_ext, trans_ext)\n",
    "file_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_in, rule_out = aihub_text.g2p.readRules(aihub_text.ver_info[0], './g2p/rulebook.txt')\n",
    "df_korSym = aihub_text.get_korean_symbol_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text, prons, labels = aihub_text.get_prons_and_labels_from_file(file_list[0], rule_in, rule_out, df_korSym, 'euc-kr', True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = transform_mfcc_from_file(file_list[0] + audio_ext, \\\n",
    "                                       endian='int16', sr=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/KsponSpeech_sample/KsponSpeech_000001\n",
      "아/ 몬 소리야, 그건 또. b/\n",
      "|aa [GANTU] |mm oo nf |s0 oo rr ii ya |k0 xx k0 vv nf |tt oo | [NOISE:b]\n",
      "[8, 57, 3, 0, 24, 61, 40, 0, 18, 61, 26, 54, 64, 0, 15, 58, 15, 59, 40, 0, 14, 61, 0, 4, 8]\n"
     ]
    }
   ],
   "source": [
    "print(file_list[0])\n",
    "print(text)\n",
    "print(prons)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save dataset as TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.python_io.TFRecordOptions(compression_type=tf.python_io.TFRecordCompressionType.GZIP)\n",
    "writer = tf.python_io.TFRecordWriter(path=\"./tfrecord/tfrecord_practice.tfrecords\", options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:00<00:05, 16.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start converting...\n",
      "data/KsponSpeech_sample/KsponSpeech_000001 (314, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000002 (1058, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000003 (1231, 39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:00<00:05, 17.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/KsponSpeech_sample/KsponSpeech_000004 (912, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000005 (506, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000006 (385, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000007 (1208, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000008 (128, 39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [00:00<00:03, 22.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/KsponSpeech_sample/KsponSpeech_000009 (632, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000010 (305, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000011 (354, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000012 (586, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000013 (284, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000014 (458, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000015 (647, 39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [00:00<00:03, 23.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/KsponSpeech_sample/KsponSpeech_000016 (278, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000017 (370, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000018 (336, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000019 (492, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000020 (828, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000021 (113, 39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [00:01<00:02, 25.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/KsponSpeech_sample/KsponSpeech_000022 (516, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000023 (926, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000024 (772, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000025 (216, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000026 (159, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000027 (480, 39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 30/100 [00:01<00:02, 24.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/KsponSpeech_sample/KsponSpeech_000028 (270, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000029 (112, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000030 (1496, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000031 (485, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000032 (128, 39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [00:01<00:02, 28.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/KsponSpeech_sample/KsponSpeech_000033 (728, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000034 (433, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000035 (269, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000036 (127, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000037 (882, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000038 (173, 39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 41/100 [00:01<00:02, 27.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/KsponSpeech_sample/KsponSpeech_000039 (955, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000040 (399, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000041 (321, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000042 (137, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000043 (169, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000044 (168, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000045 (161, 39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/100 [00:01<00:01, 25.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/KsponSpeech_sample/KsponSpeech_000046 (805, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000047 (193, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000048 (434, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000049 (993, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000050 (248, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000051"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 53/100 [00:02<00:01, 28.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (258, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000052 (178, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000053 (419, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000054 (211, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000055 (594, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000056 (841, 39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 59/100 [00:02<00:02, 19.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/KsponSpeech_sample/KsponSpeech_000057 (202, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000058 (2914, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000059 (225, 39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 66/100 [00:02<00:01, 24.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/KsponSpeech_sample/KsponSpeech_000060 (509, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000061 (208, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000062 (429, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000063 (207, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000064 (364, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000065 (662, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000066 (583, 39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 69/100 [00:02<00:01, 23.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/KsponSpeech_sample/KsponSpeech_000067 (456, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000068 (1460, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000069 (537, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000070 (769, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000071 (219, 39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 75/100 [00:03<00:01, 22.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/KsponSpeech_sample/KsponSpeech_000072 (424, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000073 (371, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000074 (426, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000075 (1706, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000076 (600, 39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 81/100 [00:03<00:00, 24.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/KsponSpeech_sample/KsponSpeech_000077 (160, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000078 (1042, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000079 (235, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000080 (1162, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000081 (316, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000082 (227, 39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90/100 [00:03<00:00, 29.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/KsponSpeech_sample/KsponSpeech_000083 (324, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000084 (384, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000085 (575, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000086 (316, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000087 (126, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000088 (612, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000089 (147, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000090 (259, 39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 95/100 [00:03<00:00, 32.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/KsponSpeech_sample/KsponSpeech_000091 (262, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000092 (407, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000093 (273, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000094 (264, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000095 (208, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000096 (617, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000097 (672, 39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 25.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/KsponSpeech_sample/KsponSpeech_000098 (297, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_000099 (1276, 39)\n",
      "data/KsponSpeech_sample/KsponSpeech_001000 (358, 39)\n",
      "Done...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Start converting...\")\n",
    "for f in tqdm(file_list):\n",
    "    feat = transform_mfcc_from_file(f + audio_ext, \\\n",
    "                                       endian='int16', sr=16000)\n",
    "    text, prons, labels = aihub_text.get_prons_and_labels_from_file(file_list[0], rule_in, rule_out, df_korSym, 'euc-kr', True, True)\n",
    "    \n",
    "    example = tf.train.Example(\n",
    "        features=tf.train.Features(\n",
    "            feature={\n",
    "                \"file_name\": _bytes_feature(f.encode('utf-8')),\n",
    "                \"feature\": _bytes_feature(feat.tostring()),\n",
    "                \"trans\": _bytes_feature(text.encode('utf-8')),\n",
    "                \"prons\": _bytes_feature(prons.encode('utf-8')),\n",
    "                \"label\": _bytes_feature(np.array(labels).tostring())\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    print(f, feat.shape)\n",
    "    writer.write(example.SerializeToString())\n",
    "    \n",
    "writer.close()\n",
    "print(\"Done...\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset from TFRecords file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_tfrecord(serialized):\n",
    "    features = tf.parse_single_example(\n",
    "        serialized=serialized,\n",
    "#         features={\n",
    "#             \"file_name\": tf.VarLenFeature(tf.string),\n",
    "#             \"feature\": tf.VarLenFeature(tf.string),\n",
    "#             \"trans\": tf.VarLenFeature(tf.string),\n",
    "#             \"prons\": tf.VarLenFeature(tf.string),\n",
    "#             \"label\": tf.VarLenFeature(tf.string)\n",
    "#         }\n",
    "        features={\n",
    "            \"file_name\": tf.FixedLenFeature([], tf.string),\n",
    "            \"feature\": tf.FixedLenFeature([], tf.string),\n",
    "            \"trans\": tf.FixedLenFeature([], tf.string),\n",
    "            \"prons\": tf.FixedLenFeature([], tf.string),\n",
    "            \"label\": tf.FixedLenFeature([], tf.string)\n",
    "        }\n",
    "    )\n",
    "#     file_name = tf.decode_raw(features['file_name'], tf.string)\n",
    "    file_name = features['file_name']\n",
    "    feature = tf.decode_raw(features['feature'], tf.float32)\n",
    "    #feature = tf.reshape(tf.decode_raw(features['feature'], tf.float32), [-1, 39])\n",
    "#     trans = tf.decode_raw(features['trans'], tf.string)\n",
    "    trans = features['trans']\n",
    "#     prons = tf.decode_raw(features['prons'], tf.string)\n",
    "    prons = features['prons']\n",
    "    labels = tf.decode_raw(features['label'], tf.int16)\n",
    "    \n",
    "    return file_name, feature, trans, prons, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.TFRecordDataset(filenames=\"tfrecord/tfrecord_practice.tfrecords\",\n",
    "                                 compression_type=\"GZIP\").map(from_tfrecord)\n",
    "g_fname, g_feature, g_trans, g_prons, g_labels = dataset.batch(2).shuffle(10).repeat(10).make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot batch tensors with different shapes in component 1. First element had shape [24492] and element 1 had shape [82524].\n\t [[Node: IteratorGetNext_11 = IteratorGetNext[output_shapes=[[?], [?,?], [?], [?], [?,?]], output_types=[DT_STRING, DT_FLOAT, DT_STRING, DT_STRING, DT_INT16], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_11)]]\n\nCaused by op 'IteratorGetNext_11', defined at:\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 583, in start\n    self.io_loop.start()\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 149, in start\n    self.asyncio_loop.run_forever()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 1426, in _run_once\n    handle._run()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2858, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2886, in _run_cell\n    return runner(coro)\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3063, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3254, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-73-4bb0f19d8678>\", line 3, in <module>\n    g_fname, g_feature, g_trans, g_prons, g_labels = dataset.batch(2).shuffle(10).repeat(10).make_one_shot_iterator().get_next()\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 410, in get_next\n    name=name)), self._output_types,\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 2069, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot batch tensors with different shapes in component 1. First element had shape [24492] and element 1 had shape [82524].\n\t [[Node: IteratorGetNext_11 = IteratorGetNext[output_shapes=[[?], [?,?], [?], [?], [?,?]], output_types=[DT_STRING, DT_FLOAT, DT_STRING, DT_STRING, DT_INT16], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_11)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/workspace/stt/env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/stt/env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/stt/env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot batch tensors with different shapes in component 1. First element had shape [24492] and element 1 had shape [82524].\n\t [[Node: IteratorGetNext_11 = IteratorGetNext[output_shapes=[[?], [?,?], [?], [?], [?,?]], output_types=[DT_STRING, DT_FLOAT, DT_STRING, DT_STRING, DT_INT16], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_11)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-9dee94ee0a9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg_labels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/workspace/stt/env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/stt/env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/stt/env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/stt/env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1289\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot batch tensors with different shapes in component 1. First element had shape [24492] and element 1 had shape [82524].\n\t [[Node: IteratorGetNext_11 = IteratorGetNext[output_shapes=[[?], [?,?], [?], [?], [?,?]], output_types=[DT_STRING, DT_FLOAT, DT_STRING, DT_STRING, DT_INT16], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_11)]]\n\nCaused by op 'IteratorGetNext_11', defined at:\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 583, in start\n    self.io_loop.start()\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 149, in start\n    self.asyncio_loop.run_forever()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 1426, in _run_once\n    handle._run()\n  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2858, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2886, in _run_cell\n    return runner(coro)\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3063, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3254, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-73-4bb0f19d8678>\", line 3, in <module>\n    g_fname, g_feature, g_trans, g_prons, g_labels = dataset.batch(2).shuffle(10).repeat(10).make_one_shot_iterator().get_next()\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 410, in get_next\n    name=name)), self._output_types,\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 2069, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/Users/kimsu/workspace/stt/env/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot batch tensors with different shapes in component 1. First element had shape [24492] and element 1 had shape [82524].\n\t [[Node: IteratorGetNext_11 = IteratorGetNext[output_shapes=[[?], [?,?], [?], [?], [?,?]], output_types=[DT_STRING, DT_FLOAT, DT_STRING, DT_STRING, DT_INT16], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_11)]]\n"
     ]
    }
   ],
   "source": [
    "_labels = sess.run([g_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 8,  0,  0,  0, 57,  0,  0,  0,  3,  0,  0,  0,  0,  0,  0,  0,\n",
       "         24,  0,  0,  0, 61,  0,  0,  0, 40,  0,  0,  0,  0,  0,  0,  0,\n",
       "         18,  0,  0,  0, 61,  0,  0,  0, 26,  0,  0,  0, 54,  0,  0,  0,\n",
       "         64,  0,  0,  0,  0,  0,  0,  0, 15,  0,  0,  0, 58,  0,  0,  0,\n",
       "         15,  0,  0,  0, 59,  0,  0,  0, 40,  0,  0,  0,  0,  0,  0,  0,\n",
       "         14,  0,  0,  0, 61,  0,  0,  0,  0,  0,  0,  0,  4,  0,  0,  0,\n",
       "          8,  0,  0,  0]], dtype=int16)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 100)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 8,  0,  0,  0, 57,  0,  0,  0,  3,  0,  0,  0,  0,  0,  0,  0,\n",
       "         24,  0,  0,  0, 61,  0,  0,  0, 40,  0,  0,  0,  0,  0,  0,  0,\n",
       "         18,  0,  0,  0, 61,  0,  0,  0, 26,  0,  0,  0, 54,  0,  0,  0,\n",
       "         64,  0,  0,  0,  0,  0,  0,  0, 15,  0,  0,  0, 58,  0,  0,  0,\n",
       "         15,  0,  0,  0, 59,  0,  0,  0, 40,  0,  0,  0,  0,  0,  0,  0,\n",
       "         14,  0,  0,  0, 61,  0,  0,  0,  0,  0,  0,  0,  4,  0,  0,  0,\n",
       "          8,  0,  0,  0]], dtype=int16)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stt_env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation for KOREAN Datasets\n",
    ". [AIHub](http://www.aihub.or.kr/aidata/105)에서 제공되는 데이터셋에 대한 전처리 및 가공 단계를 다루는 과정입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Load\n",
    "- Audio File : 16k / PCM / 16bit LE\n",
    "- Transcript File : EUC-KR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_ext = \".pcm\"\n",
    "trans_ext = \".txt\"\n",
    "\n",
    "data_dir = \"../data/KsponSpeech_sample/\"\n",
    "data_dir = \"../data/\"\n",
    "\n",
    "SAMPLE_RATE = 16000\n",
    "ENDIAN = \"int16\"\n",
    "ENCODING = \"euc-kr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_list(path, audio_ext='.pcm', trans_ext='.txt'):\n",
    "    if not os.path.exists(path):\n",
    "        return []\n",
    "    \n",
    "    file_list = []\n",
    "    for _path, _dir, _files in os.walk(path):\n",
    "        for f in _files:\n",
    "            if f[-len(audio_ext):] == audio_ext:\n",
    "                f_name = os.path.join(_path, f[:-len(audio_ext)])\n",
    "                if os.path.exists(f_name + trans_ext):\n",
    "                    file_list.append(f_name)\n",
    "    file_list.sort()\n",
    "    \n",
    "    return file_list\n",
    "\n",
    "def get_transcript(fname, trans_ext='.txt', ENCODING='euc-kr'):\n",
    "    txt = \"\"\n",
    "    try:\n",
    "        with open(fname + trans_ext, 'r', encoding=ENCODING) as f:\n",
    "            txt = f.read().strip()\n",
    "    except Exception as e:\n",
    "        print(\"ERROR: {}\".format(e))\n",
    "    return txt\n",
    "\n",
    "def get_audiobuff(fname, audio_ext='.pcm', ENDIAN='int16'):\n",
    "    buff = None\n",
    "    try:\n",
    "        with open(fname + audio_ext, 'rb') as f:\n",
    "            buff = f.read()\n",
    "        buff = np.frombuffer(buff, dtype=ENDIAN)\n",
    "    except Exception as e:\n",
    "        print(\"ERROR: {}\".format(e))\n",
    "    return buff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Audio format.     : .pcm\n",
      " Transcript format : .txt\n",
      " Number of files   : 100\n",
      " Head of file list\n",
      "    ../data/KsponSpeech_sample/KsponSpeech_000001\n",
      "    ../data/KsponSpeech_sample/KsponSpeech_000002\n",
      "    ../data/KsponSpeech_sample/KsponSpeech_000003\n",
      "    ../data/KsponSpeech_sample/KsponSpeech_000004\n",
      "    ../data/KsponSpeech_sample/KsponSpeech_000005\n"
     ]
    }
   ],
   "source": [
    "file_list = get_file_list(data_dir, audio_ext, trans_ext)\n",
    "\n",
    "print(\" Audio format.     : {}\".format(audio_ext))\n",
    "print(\" Transcript format : {}\".format(trans_ext))\n",
    "print(\" Number of files   : {}\".format(len(file_list)))\n",
    "print(\" Head of file list\")\n",
    "for f in file_list[:5]:\n",
    "    print(\"   \", f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded trans : 아/ 몬 소리야, 그건 또. b/\n",
      " Loaded audio length : 50368\n"
     ]
    }
   ],
   "source": [
    "sample_txt = get_transcript(file_list[0])\n",
    "sample_audio = get_audiobuff(file_list[0])\n",
    "\n",
    "print(\" Loaded trans : {}\".format(sample_txt))\n",
    "print(\" Loaded audio length : {}\".format(len(sample_audio)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyze Transcript\n",
    "<b> Noise </b><br>\n",
    "- b/  : breath   -> 숨소리\n",
    "- n/  : noise    -> 노이즈\n",
    "- l/  : laugh    -> 웃음소리\n",
    "- o/  : occlude  -> 다른 사람의 목소리가 섞여있을 때\n",
    "\n",
    "<b> Number </b><br>\n",
    "ex)\n",
    "- (5대)/(오 대) 그룹이 모여, 자동차 (5대)/(다섯 대)를\n",
    "- (24시간)/(이십 사 시간), (24시간)/(스물 네 시간) -(867-860-2437)/(팔 육 칠 팔 육 공 에 이 사 삼 칠)\n",
    "- (14시)/(십 사 시), (14시)/(열 네 시)부터\n",
    "- (1999년)/(천 구백 구십 구 년)에, (1999년)/(일천 구백 구십 구 년)에\n",
    "\n",
    "<b> ETC </b><br>\n",
    "- '+' : 중복 발성     [AMBIG:DUP]\n",
    "- '*' : 불분명한 발성  [AMBIG:UNK]\n",
    "- 뭐/, 음/, 아/ 등과 같이 [한글]/ 형태의 경우 간투어를 의미함  [GANTU]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   아/ 몬 소리야, 그건 또. b/\n",
      "   나는 악습은 원래 없어진다+ 없어져야 된다고 생각하긴 했는데 근데 그/ 약간 필요악으로 하나 정도쯤은 있어야 되거든. 물 뜨러 가고.\n",
      "   b/ n/ 그래서 지호랑 계단 n/ 올라와서 b/ 막 위에 운동하는 기구 있대요. b/ 그서 그걸로 운동 할려구요. b/ n/\n",
      "   뭐/ 정신과 병원도 그 약 타서 먹어보고, 그 한동안 연락이 안 된 적이 있었단 말이야. 그때가 언제였 언제였더라?\n",
      "   o/ b/ 그게 (0.1프로)/(영 점 일 프로) 가정의 아이들과 가정의 모습이야? b/\n",
      "   그/ 친애하는 판사님께라는 법+ 법 관련 드라마 알고 있어?\n",
      "   o/ 그래가지고 진짜 차 사야겠다 아니 뭐/ 차 안 되면 스쿠터라도 타야되겠다 막/ 그런 생각 들더라구 그래서 운전은 하는 게 좋은 거 같애 진짜 b/\n",
      "   그래\n",
      "   o/ 나도 몰라. 나 그/ (3G)/(쓰리 쥐)* 하나도 안 봤음. 어.\n",
      "   아/ 내일 나 알바하구나.\n",
      "   n/ 아/ 근데 (1시)/(한 시)에 닫는 게 쫌 아쉽긴 한데 거기 진짜 괜찮은데 b/\n",
      "   맞아. 시간 안에 풀고 약간 이것부터 풀고 요런 식으로 풀어보렴. 이런 거 b/\n",
      "   삼 점대야? 언니가?\n",
      "   한+ 한+ 한 시간에 이 만 원? 거의 이 정도로 이 정도란 말이야. b/\n",
      "   굳이 싶기도 해. 까* 오히려 사원 이런 것보다는 b/ 대신 돔* 먹+ 먹, 음식 거리, 먹거리가 우리 입맛에 좀 더 맞는 거 같고.\n"
     ]
    }
   ],
   "source": [
    "for file in file_list[:15]:\n",
    "    sample_txt = get_transcript(file)\n",
    "    print(\"  \", sample_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o/ b/ 그게 (0.1프로)/(영 점 일 프로)와 (15,3프로)/(십오 점 삼 프로) 가정의 아이들과 가정의 모습이야? b/\n"
     ]
    }
   ],
   "source": [
    "sample_txt = \"o/ b/ 그게 (0.1프로)/(영 점 일 프로)와 (15,3프로)/(십오 점 삼 프로) 가정의 아이들과 가정의 모습이야? b/\"\n",
    "print(sample_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(0.1프로)/(영 점 일 프로)', '(15,3프로)/(십오 점 삼 프로)']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = re.findall(\"\\(.+?\\)/\\(.+?\\)\", sample_txt)\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normStep1(txt):\n",
    "    # (0.1프로)/(영 점 일 프로) or (3G)/(쓰리 쥐) or (1시)/(한 시) 등과 같은\n",
    "    # (실제 표기)/(발음 표기) 형태의 데이터를 발음 표기의 데이터로 치환하는 함수\n",
    "    args = re.findall(\"\\(.+?\\)/\\(.+?\\)\", txt)\n",
    "    for arg in args:\n",
    "        _arg = re.sub(\"\\(.+?\\)/\", \"\", arg)\n",
    "        _arg = re.sub(\"[\\(\\)]\", \"\", _arg)\n",
    "        txt = txt.replace(arg, _arg)\n",
    "    return txt\n",
    "\n",
    "def normStep2(txt):\n",
    "    # . , ? 등 특수문자 제거\n",
    "    txt = re.sub(\"[.,?]\", \"\", txt)\n",
    "    return txt\n",
    "\n",
    "def normStep3(txt):\n",
    "    # noise symbol을 [NOISE:o], [NOIST:b] 등과 같이 변환\n",
    "    symbol_list = re.findall(\"[a-z]/\", txt)\n",
    "    for symbol in symbol_list:\n",
    "        _symbol = symbol.replace('/', '')\n",
    "        new_symbol = \"[NOISE:{}]\".format(_symbol)\n",
    "        txt = txt.replace(symbol, new_symbol)\n",
    "    return txt\n",
    "\n",
    "def normStep4(txt):\n",
    "    # +, *와 같은 불분명한 symbol에 대한 전처리\n",
    "    txt = re.sub(\"[\\+]\", \"[AMBIG:DUP]\", txt)\n",
    "    txt = re.sub(\"[\\*]\", \"[AMBIG:UNK]\", txt)\n",
    "    return txt\n",
    "    \n",
    "def normStep5(txt):\n",
    "    # 뭐/ 아/ 와 같은 간투어 처리\n",
    "    for _txt in txt.split():\n",
    "        symbol_list = re.findall(\"[가-힣].*?/\", _txt)\n",
    "        for symbol in symbol_list:\n",
    "            new_symbol = symbol.replace('/', '[GANTU]')\n",
    "            txt = txt.replace(symbol, new_symbol)\n",
    "    return txt\n",
    "\n",
    "def normalize(txt):\n",
    "    # step1 : to pronunciation\n",
    "    txt = normStep1(txt)\n",
    "    # step2 : erase special symbol\n",
    "    txt = normStep2(txt)\n",
    "    # step3 : noise tagging\n",
    "    txt = normStep3(txt)\n",
    "    # step4 : ambiguous symbol tagging\n",
    "    txt = normStep4(txt)\n",
    "    # step5 : tagging for GANTU symbol\n",
    "    txt = normStep5(txt)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: 'euc_kr' codec can't decode byte 0x98 in position 68: illegal multibyte sequence\n"
     ]
    }
   ],
   "source": [
    "txt_norm_list = []\n",
    "for file in file_list:\n",
    "    txt = get_transcript(file)\n",
    "    txt_norm = normalize(txt)\n",
    "    \n",
    "    txt_norm_list.append(txt_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0] input : 아/ 몬 소리야, 그건 또. b/\n",
      "     norm  : 아[GANTU] 몬 소리야 그건 또 [NOISE:b]\n",
      "\n",
      "[ 1] input : 나는 악습은 원래 없어진다+ 없어져야 된다고 생각하긴 했는데 근데 그/ 약간 필요악으로 하나 정도쯤은 있어야 되거든. 물 뜨러 가고.\n",
      "     norm  : 나는 악습은 원래 없어진다[AMBIG:DUP] 없어져야 된다고 생각하긴 했는데 근데 그[GANTU] 약간 필요악으로 하나 정도쯤은 있어야 되거든 물 뜨러 가고\n",
      "\n",
      "[ 2] input : b/ n/ 그래서 지호랑 계단 n/ 올라와서 b/ 막 위에 운동하는 기구 있대요. b/ 그서 그걸로 운동 할려구요. b/ n/\n",
      "     norm  : [NOISE:b] [NOISE:n] 그래서 지호랑 계단 [NOISE:n] 올라와서 [NOISE:b] 막 위에 운동하는 기구 있대요 [NOISE:b] 그서 그걸로 운동 할려구요 [NOISE:b] [NOISE:n]\n",
      "\n",
      "[ 3] input : 뭐/ 정신과 병원도 그 약 타서 먹어보고, 그 한동안 연락이 안 된 적이 있었단 말이야. 그때가 언제였 언제였더라?\n",
      "     norm  : 뭐[GANTU] 정신과 병원도 그 약 타서 먹어보고 그 한동안 연락이 안 된 적이 있었단 말이야 그때가 언제였 언제였더라\n",
      "\n",
      "[ 4] input : o/ b/ 그게 (0.1프로)/(영 점 일 프로) 가정의 아이들과 가정의 모습이야? b/\n",
      "     norm  : [NOISE:o] [NOISE:b] 그게 영 점 일 프로 가정의 아이들과 가정의 모습이야 [NOISE:b]\n",
      "\n",
      "[ 5] input : 그/ 친애하는 판사님께라는 법+ 법 관련 드라마 알고 있어?\n",
      "     norm  : 그[GANTU] 친애하는 판사님께라는 법[AMBIG:DUP] 법 관련 드라마 알고 있어\n",
      "\n",
      "[ 6] input : o/ 그래가지고 진짜 차 사야겠다 아니 뭐/ 차 안 되면 스쿠터라도 타야되겠다 막/ 그런 생각 들더라구 그래서 운전은 하는 게 좋은 거 같애 진짜 b/\n",
      "     norm  : [NOISE:o] 그래가지고 진짜 차 사야겠다 아니 뭐[GANTU] 차 안 되면 스쿠터라도 타야되겠다 막[GANTU] 그런 생각 들더라구 그래서 운전은 하는 게 좋은 거 같애 진짜 [NOISE:b]\n",
      "\n",
      "[ 7] input : 그래\n",
      "     norm  : 그래\n",
      "\n",
      "[ 8] input : o/ 나도 몰라. 나 그/ (3G)/(쓰리 쥐)* 하나도 안 봤음. 어.\n",
      "     norm  : [NOISE:o] 나도 몰라 나 그[GANTU] 쓰리 쥐[AMBIG:UNK] 하나도 안 봤음 어\n",
      "\n",
      "[ 9] input : 아/ 내일 나 알바하구나.\n",
      "     norm  : 아[GANTU] 내일 나 알바하구나\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, file in enumerate(file_list[:10]):\n",
    "    txt = get_transcript(file)\n",
    "    txt_norm = normalize(txt)\n",
    "    \n",
    "    print(\"[{0:2d}] input : {1}\".format(i, txt))\n",
    "    print(\"     norm  : {}\".format(txt_norm))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convert normalized transcript to lexical pronunciation symbol using G2P."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')   # To import parent dir's packages\n",
    "\n",
    "from g2p import g2p\n",
    "ver_info = sys.version_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kor2pron(txt, rule_in, rule_out):\n",
    "    pron_list = []\n",
    "    for w in txt.split():\n",
    "        tag = re.findall('(\\[.+?\\])', w)\n",
    "        if tag:\n",
    "            pron_list.append(w)\n",
    "        else:\n",
    "            prons = g2p.graph2prono(w, rule_in, rule_out)\n",
    "            pron_list.append(prons)\n",
    "    pronun_txt = \" |\".join(pron_list)\n",
    "    \n",
    "    return pronun_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "[rule_in, rule_out] = g2p.readRules(ver_info[0], '../g2p/rulebook.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Origin Txt: 아[GANTU] 몬 소리야 그건 또 [NOISE:b]\n",
      "  Pronon Txt: 아[GANTU] |mm oo nf |s0 oo rr ii ya |k0 xx k0 vv nf |tt oo |[NOISE:b]\n",
      "> Origin Txt: 나는 악습은 원래 없어진다[AMBIG:DUP] 없어져야 된다고 생각하긴 했는데 근데 그[GANTU] 약간 필요악으로 하나 정도쯤은 있어야 되거든 물 뜨러 가고\n",
      "  Pronon Txt: nn aa nn xx nf |aa kf ss xx p0 xx nf |wv ll rr qq |없어진다[AMBIG:DUP] |vv pf ss vv c0 yv ya |t0 wo nf t0 aa k0 oo |s0 qq ng k0 aa kh aa k0 ii nf |h0 qq nf nn xx nf t0 ee |k0 xx nf t0 ee |그[GANTU] |ya kf kk aa nf |ph ii ll rr yo aa k0 xx rr oo |h0 aa nn aa |c0 vv ng t0 oo cc xx mm xx nf |ii ss vv ya |t0 wo k0 vv t0 xx nf |mm uu ll |tt xx rr vv |k0 aa k0 oo\n",
      "> Origin Txt: [NOISE:b] [NOISE:n] 그래서 지호랑 계단 [NOISE:n] 올라와서 [NOISE:b] 막 위에 운동하는 기구 있대요 [NOISE:b] 그서 그걸로 운동 할려구요 [NOISE:b] [NOISE:n]\n",
      "  Pronon Txt: [NOISE:b] |[NOISE:n] |k0 xx rr qq s0 vv |c0 ii h0 oo rr aa ng |k0 ye t0 aa nf |[NOISE:n] |oo ll rr aa wa s0 vv |[NOISE:b] |mm aa kf |wi ee |uu nf t0 oo ng h0 aa nn xx nf |k0 ii k0 uu |ii tf tt qq yo |[NOISE:b] |k0 xx s0 vv |k0 xx k0 vv ll rr oo |uu nf t0 oo ng |h0 aa ll rr yv k0 uu yo |[NOISE:b] |[NOISE:n]\n",
      "> Origin Txt: 뭐[GANTU] 정신과 병원도 그 약 타서 먹어보고 그 한동안 연락이 안 된 적이 있었단 말이야 그때가 언제였 언제였더라\n",
      "  Pronon Txt: 뭐[GANTU] |c0 vv ng s0 ii nf kk wa |p0 yv ng wv nf t0 oo |k0 xx |ya kf |th aa s0 vv |mm vv k0 vv p0 oo k0 oo |k0 xx |h0 aa nf t0 oo ng aa nf |yv ll rr aa k0 ii |aa nf |t0 wo nf |c0 vv k0 ii |ii ss vv tf tt aa nf |mm aa rr ii ya |k0 xx tt qq k0 aa |vv nf c0 ee yv tf |vv nf c0 ee yv tf tt vv rr aa\n",
      "> Origin Txt: [NOISE:o] [NOISE:b] 그게 영 점 일 프로 가정의 아이들과 가정의 모습이야 [NOISE:b]\n",
      "  Pronon Txt: [NOISE:o] |[NOISE:b] |k0 xx k0 ee |yv ng |c0 vv mf |ii ll |ph xx rr oo |k0 aa c0 vv ng xi |aa ii t0 xx ll k0 wa |k0 aa c0 vv ng xi |mm oo s0 xx p0 ii ya |[NOISE:b]\n",
      "> Origin Txt: 그[GANTU] 친애하는 판사님께라는 법[AMBIG:DUP] 법 관련 드라마 알고 있어\n",
      "  Pronon Txt: 그[GANTU] |ch ii nn qq h0 aa nn xx nf |ph aa nf s0 aa nn ii mf kk ee rr aa nn xx nf |법[AMBIG:DUP] |p0 vv pf |k0 wa ll rr yv nf |t0 xx rr aa mm aa |aa ll k0 oo |ii ss vv\n",
      "> Origin Txt: [NOISE:o] 그래가지고 진짜 차 사야겠다 아니 뭐[GANTU] 차 안 되면 스쿠터라도 타야되겠다 막[GANTU] 그런 생각 들더라구 그래서 운전은 하는 게 좋은 거 같애 진짜 [NOISE:b]\n",
      "  Pronon Txt: [NOISE:o] |k0 xx rr qq k0 aa c0 ii k0 oo |c0 ii nf cc aa |ch aa |s0 aa ya k0 ee tf tt aa |aa nn ii |뭐[GANTU] |ch aa |aa nf |t0 wo mm yv nf |s0 xx kh uu th vv rr aa t0 oo |th aa ya t0 wo k0 ee tf tt aa |막[GANTU] |k0 xx rr vv nf |s0 qq ng k0 aa kf |t0 xx ll t0 vv rr aa k0 uu |k0 xx rr qq s0 vv |uu nf c0 vv nn xx nf |h0 aa nn xx nf |k0 ee |c0 oo xx nf |k0 vv |k0 aa th qq |c0 ii nf cc aa |[NOISE:b]\n",
      "> Origin Txt: 그래\n",
      "  Pronon Txt: k0 xx rr qq\n",
      "> Origin Txt: [NOISE:o] 나도 몰라 나 그[GANTU] 쓰리 쥐[AMBIG:UNK] 하나도 안 봤음 어\n",
      "  Pronon Txt: [NOISE:o] |nn aa t0 oo |mm oo ll rr aa |nn aa |그[GANTU] |ss xx rr ii |쥐[AMBIG:UNK] |h0 aa nn aa t0 oo |aa nf |p0 wa ss xx mf |vv\n",
      "> Origin Txt: 아[GANTU] 내일 나 알바하구나\n",
      "  Pronon Txt: 아[GANTU] |nn qq ii ll |nn aa |aa ll p0 aa h0 aa k0 uu nn aa\n"
     ]
    }
   ],
   "source": [
    "for txt in txt_norm_list[:10]:\n",
    "    pron_txt = kor2pron(txt, rule_in, rule_out)\n",
    "    \n",
    "    print(\"> Origin Txt: {}\".format(txt))\n",
    "    print(\"  Pronon Txt: {}\".format(pron_txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nn ee'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g2p.graph2prono(\"네\", rule_in, rule_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, file in enumerate(file_list[:10]):\n",
    "    txt = get_transcript(file)\n",
    "    txt_norm = normalize(txt)\n",
    "    print(\"[{0:2d}] input : {1}\".format(i, txt_norm))\n",
    "    print(\"     pronun : {}\".format(txt_norm))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stt_env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
